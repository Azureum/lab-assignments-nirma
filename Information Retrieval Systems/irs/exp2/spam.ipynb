{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,meta = arff.loadarff('spambase.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(data)\n",
    "#print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "<class 'numpy.void'>\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "train = data[:3000]\n",
    "test = data[3000:]\n",
    "print(train.shape)\n",
    "print(type(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train['is_spam']\n",
    "#print(trainY)\n",
    "\n",
    "names = list(train.dtype.names)\n",
    "trainX = train[names[:57]]\n",
    "#print(trainX)\n",
    "\n",
    "testY = test['is_spam']\n",
    "#print(testY)\n",
    "\n",
    "testX = test[names[:57]]\n",
    "#print(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "print(trainY.shape)\n",
    "\n",
    "trainX = np.array(trainX.tolist())\n",
    "testX = np.array(testX.tolist())\n",
    "#print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[648 171]\n",
      " [127 655]]\n",
      "Accuracy =  0.813866333542\n",
      "Precision = 79.1208791209\n",
      "Recall= 83.6129032258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.81505224001069787, 0.81386633354153659, 0.81384396687375038, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "model = MultinomialNB()\n",
    "model.fit(trainX,trainY)\n",
    "prediction = model.predict(testX)\n",
    "conf = confusion_matrix(testY,prediction)\n",
    "print(conf)\n",
    "accuracy = (conf[0][0] + conf[1][1])/(conf[0][0] + conf[1][1] + conf[0][1] + conf[1][0]) \n",
    "print('Accuracy = ',accuracy)\n",
    "precision = conf[0][0]/(conf[0][0] + conf[0][1])*100\n",
    "recall = conf[0][0]/(conf[0][0] + conf[1][0])*100\n",
    "\n",
    "print('Precision =', precision )\n",
    "print('Recall=', recall)\n",
    "precision_recall_fscore_support(testY, prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[744  75]\n",
      " [ 86 696]]\n",
      "Accuracy =  0.899437851343\n",
      "Precision = 90.8424908425\n",
      "Recall= 89.6385542169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.89948139920402181, 0.89943785134291065, 0.89941711766463672, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = BernoulliNB()\n",
    "model2.fit(trainX,trainY)\n",
    "prediction = model2.predict(testX)\n",
    "conf = confusion_matrix(testY,prediction)\n",
    "print(conf)\n",
    "accuracy = (conf[0][0] + conf[1][1])/(conf[0][0] + conf[1][1] + conf[0][1] + conf[1][0]) \n",
    "print('Accuracy = ',accuracy)\n",
    "precision = conf[0][0]/(conf[0][0] + conf[0][1])*100\n",
    "recall = conf[0][0]/(conf[0][0] + conf[1][0])*100\n",
    "\n",
    "print('Precision =', precision )\n",
    "print('Recall=', recall)\n",
    "precision_recall_fscore_support(testY, prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[640 179]\n",
      " [ 36 746]]\n",
      "Accuracy =  0.865708931918\n",
      "Precision = 78.1440781441\n",
      "Recall= 94.674556213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.87823675691258452, 0.86570893191755149, 0.86491127834080039, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = GaussianNB()\n",
    "model3.fit(trainX,trainY)\n",
    "prediction = model3.predict(testX)\n",
    "conf = confusion_matrix(testY,prediction)\n",
    "print(conf)\n",
    "accuracy = (conf[0][0] + conf[1][1])/(conf[0][0] + conf[1][1] + conf[0][1] + conf[1][0]) \n",
    "print('Accuracy = ',accuracy)\n",
    "precision = conf[0][0]/(conf[0][0] + conf[0][1])*100\n",
    "recall = conf[0][0]/(conf[0][0] + conf[1][0])*100\n",
    "\n",
    "print('Precision =', precision )\n",
    "print('Recall=', recall)\n",
    "precision_recall_fscore_support(testY, prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478 341]\n",
      " [ 12 770]]\n",
      "Accuracy =  0.779512804497\n",
      "Precision = 58.3638583639\n",
      "Recall= 97.5510204082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.83755343857755105, 0.77951280449718929, 0.77096465985204121, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LinearSVC()\n",
    "model4.fit(trainX,trainY)\n",
    "prediction = model4.predict(testX)\n",
    "conf = confusion_matrix(testY,prediction)\n",
    "print(conf)\n",
    "accuracy = (conf[0][0] + conf[1][1])/(conf[0][0] + conf[1][1] + conf[0][1] + conf[1][0]) \n",
    "print('Accuracy = ',accuracy)\n",
    "precision = conf[0][0]/(conf[0][0] + conf[0][1])*100\n",
    "recall = conf[0][0]/(conf[0][0] + conf[1][0])*100\n",
    "\n",
    "print('Precision =', precision )\n",
    "print('Recall=', recall)\n",
    "precision_recall_fscore_support(testY, prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
